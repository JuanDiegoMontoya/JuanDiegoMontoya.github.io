<!doctype html>
<html>
  <head>
    <title>Particles II</title>
    <link rel="icon" href="../assets/icon.png">
    <link rel="stylesheet" href="../style.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../highlight/styles/night-owl.min.css">
    <script src="../highlight/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
  </head>
  <body>
    <ul class="headerBar">
      <li class="headerli"><a href="../index.html">Home</a></li>
      <li class="headerli"><a href="../blog.html">Blog</a></li>
      <li class="headerli"><a href="../projects.html">Projects</a></li>
      <li class="headerli"><a href="../about.html">About</a></li>
    </ul>
    <h1>A Fast and Simple Particle System, Part 2</h1>
    <ol>
      <li>Introduction</li>
      <li>Vertex Shader</li>
      <li>Index List and Indirect Drawing</li>
      <li>Particle Culling</li>
      <li>Compaction</li>
      <li>SoA Layout</li>
      <li>Shared Memory</li>
      <li>Future Work</li>
    </ol>
    <h2>Introduction</h2>
    <p>
      The previous post in the series discussed motivation, and basic implementations (CPU and GPU) of a billboard particle system for 3D games. Here, we will discuss optimizations.
    </p>
    <h2>Vertex Shader</h2>
    <p>
      What if we didn't have to read any vertex data in our vertex shader?
    </p>
    <pre><code class="language-glsl">
#version 460 core

... // declarations

layout(location = 0) out vec2 vTexCoord;

// triangle fan with vertices in [0, 1]
// 0x3 == 0b1100
// 0x9 == 0b1001
// `b` selects which two bits will be used
vec2 CreateQuad(in uint vertexID) {
    uint b = 1 &lt&lt vertexID;
    return vec2((0x3 & b) != 0, (0x9 & b) != 0);
}

void main() {
    vTexCoord = CreateQuad(gl_VertexID);
    vec2 aPos = vTexCoord - 0.5;

    ... // calculate gl_Position
}
    </code></pre>
    <p>
      We use the clever technique of encoding vertex positions into consecutive bits inspired by <a href="https://twitter.com/Donzanoid/status/616370134278606848" class="link">this post</a>. Invoking the shader remains simple as before.
    </p>
    <pre><code>
void BeginRenderParticleEmitters() {
    glUseProgram(particleShader);
    /* set uniforms */
    glBindVertexArray(emptyVAO); // no vertex attributes needed!
}

void RenderParticleEmitter(const ParticleEmitter& emitter) {
    glBindBuffer(GL_SHADER_STORAGE_BUFFER, emitter.particleBuffer);
    glBindBufferBase(GL_SHADER_STORAGE_BUFFER, 0);
    glDrawArraysInstanced(GL_TRIANGLE_FAN, 0, 4, emitter.maxParticles);
}
    </code></pre>
    <p>
      This isn't necessarily a performance optimization, as we may be subverting the hardware's post-transform cache, or, more precisely, <a href="https://arbook.icg.tugraz.at/schmalstieg/Schmalstieg_351.pdf" class="link">a form of batching</a>. The performance benefits are admittedly theoretical, but fan primitives contain enough information to get the same vertex reuse benefits as indexed drawing. However, we can say with certainty that are avoiding the memory access required for reading a vertex and index buffer, which has a cost of its own.
    </p>
    <h2>Index List and Indirect Drawing</h2>
    <p>
      One inefficiency caused by moving to a GPU-driven solution is that the CPU no longer knows how many particles are alive at a time. To account for this, we always draw the maximum number of particles an emitter holds, then discard primitives in the vertex shader (by outputting degenerate triangles).
    </p>
    <p>
      Modern graphics APIs allow us to solve this problem by introducing a concept called <a href="https://www.khronos.org/opengl/wiki/Vertex_Rendering#Indirect_rendering" class="link">indirect rendering</a>, which allows the driver to source draw arguments from a buffer on the GPU. On its own this won't help us, because our particles are not ordered. Consider the case where some particles die.
    </p>
    <img src="https://i.imgur.com/oD66ba9.png">
    <img src="https://i.imgur.com/ZrkUefd.png">
    <p>
      You can see that even if we know the number of particles that are alive, we do not know where they are. The solution to this problem is, as usual, <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_software_engineering" class="link">an extra level of indirection</a>.
    </p>
    <p>
      We introduce a buffer called <code>drawIndices</code> which holds the indices of particles to be drawn that frame. The buffer appears in the update shader as such:
    </p>
    <pre><code class="language-glsl">layout(std430, binding = 5) restrict buffer Drawindices {
    uint drawIndices[];
};  </code></pre>
    <p>
      Being an append/stack-style buffer, you may be wondering where the count is located. It can be found in the <code>instanceCount</code> field of the indirect draw buffer.
    </p>
    <pre><code class="language-glsl">struct DrawArraysCommand {
  uint count;
  uint instanceCount;
  uint first;
  uint baseInstance;
};

layout(std430, binding = 4) coherent restrict buffer IndirectCommand {
  DrawArraysCommand indirectCommand;
};  </code></pre>
    <p>
      Every frame before updating particles, we clear the instance count on the CPU. This is trivial in any API and does not introduce a sync point.
    </p>
    <pre><code class="language-glsl">uint32_t zero{ 0 };
glClearNamedBufferSubData(emitter.indirectDrawBuffer, GL_R32UI,
                          offsetof(DrawArraysIndirectCommand, instanceCount),
                          sizeof(uint32_t), GL_RED, GL_UNSIGNED_INT, &zero);</code></pre>
    <p>
      Then, in the update shader, we can append to the buffer when a particle is alive this frame.
    </p>
    <pre><code class="language-glsl">
void UpdateParticle(inout Particle particle, int i) {
    if (particle.life &lt= 0.0)
      return;

    particle.velocity += particle.acceleration * u_dt;
    particle.position += particle.velocity * u_dt;
    particle.life -= u_dt;
    if (particle.life &lt= 0.0) { // particle died this frame
        int freeIndex = atomicAdd(freeCount, 1);
        freeIndices[freeIndex] = i;
    }
    // ## NEW ##
    else { // particle is alive, so we will render it (add its index to drawIndices)
        uint drawIndex = atomicAdd(indirectCommand.instanceCount, 1);
        drawIndices[drawIndex] = i;
    }
}
    </code></pre>
    <p>
      Finally, in the vertex shader, we use <code>gl_InstanceID</code> to index our draw indices rather than indexing the particle buffer directly.
    </p>
    <pre><code class="language-glsl">Particle particle = particles[drawIndices[gl_InstanceID]];</code></pre>
    <p>
      With this, we gained the ability to select which particles are drawn on a per-particle basis. However, we actually introduced a problem with this! With the extra layer of indirection, we have made it so that the vertex shader no longer accesses the particle array in a predictable manner, as two adjacent indices may point to any particle in the array. When nearly all particles are alive, we do not get much benefit from using indices, and the incoherent accesses will cause more cache misses than before.
    </p>
    <p>
      We will see in the next section how we gain much more than we lose with this
    </p>
    <h2>Particle Culling</h2>
    <p>

    </p>
    <h2>Compaction</h2>
    <p>
      You might've noticed by now that we're wasting quite a bit of space with the current particle struct layout. Currently, each particle instance is 80 bytes.
    </p>
    <pre><code class="language-glsl">
struct Particle
{
    vec4 position;
    vec4 velocity;
    vec4 acceleration;
    vec4 color;
    vec2 scale;
    float life;
    int padding_01;
};
    </code></pre>
    <p>
      For one, <code>position</code>, <code>velocity</code>, and <code>acceleration</code> each waste a float for the sake of alignment. Second, we probably don't need a full 32-bit float for storing velocity and acceleration. Scale also doesn't need very much precision as it will be in very small range near zero practically 100% of the time.
    </p>
    <p>
      With that in mind, I think we can do with just <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format#IEEE_754_half-precision_binary_floating-point_format:_binary16" class="link">3.3 decimal digits of precison</a> with no major loss in quality by using half floats. Similarly, <code>color</code> does not need to be four full-precision floats. Since it stores diffuse RGB and alpha, we can use regular normalized 8-bit unsigned integers easily. We'll be taking advantage of GLSL's packing and unpacking functions to make this work.
    </p>
    <p>
      Here's the improved result:
    </p>
    <pre><code class="language-glsl">
struct Particle
{
    // accessed as normal
    vec3 position;

    // four bytes of padding

    // unpackHalf2x16 x 3 to access vel/accel, uintBitsToFloat(.w) to access life
    uvec4 velocity_acceleration_life;

    // unpackHalf2x16 to access scale, unpackUnorm4x8 to access color
    uvec2 packedScale_packedColor;

    // eight hidden bytes of padding O_o
};
    </code></pre>
    <p>
      It ain't pretty, but we managed to reduce the size of our data by half to 40 bytes. Ignoring the hidden alignment, I'd say that's pretty good! This should give us a substantial improvement in update and rendering times because we can utilize our limited bandwidth more efficiently.
    </p>
    <p>
      Now, why did I ignore that hidden alignment? Because there is another optimization that can be made with regards to the layout that will let us ignore it and give other gains.
    </p>
    <h2>SoA Layout</h2>
    <p>
      The big daddy of data-oriented programming appears once again. So, why would we care about organizing our data into a struct of arrays instead of one array containing all of the data for a particle? To answer that question, let's take a look at how our memory access pattern utilizes the L1 cache. Here, we pretend a cache line is 64 bytes. This is true for some architectures, like GCN, but not for others. The same concepts apply in any case.
    </p>
    <img src="https://i.imgur.com/ez6N68V.png">
    <p>
      We need to fetch four cache lines in order to access six particle instances in one thread. Note that each particle requires 56.25% (36/64 bytes) of a cache line, so about every 1.8 particles read, there is a cache miss. Well, if we use all of the data we fetch in the cache, then we have no choice but to accept this cost. Well, let's take a look at the data we access in the particle update shader. (I'm ignoring that position needs a fourth component for alignment. It is omitted here for simplicity)
    </p>
    <img src="https://i.imgur.com/BZtOVOy.png">
    <p>
      It looks like we're wasting eight whole bytes of cache per particle we read because the scale and color remain constant. That is 29% more cache misses than necessary.
    </p>
    <img src="https://i.imgur.com/gFJGtwZ.png">
    <p>
      The case is even worse for the vertex shader. Nearly half the data fetched is wasted as we only need position, scale, and color for rendering.
    </p>
    <p>
      The solution to this problem is hinted at by the name of this section: <strong>SoA Layout</strong>. By separating particle data into different arrays based on access, we can make maximum use of the caches provided to us.
    </p>
    <pre><code class="language-glsl">// accessed in update and vertex shader
struct ParticleSharedData {
    vec3 position;
};

// accessed in update shader only
struct ParticleUpdateData {
    uvec4 velocity_acceleration_life;
};

// accessed in vertex shader only
struct ParticleRenderData {
    uvec2 scaleX_colorY;
};  </code></pre>
    <p>
      And how this looks in memory when packed into separate buffers...
    </p>
    <img src="https://i.imgur.com/1wm2eoB.png">
    <p>
      Now, getting efficient cache behavior is as simple as fetching only the data we require in a shader.
    </p>
    <img src="https://i.imgur.com/JyHamxP.png">
    <img src="https://i.imgur.com/i2cfNKN.png">
    <h2>Future Work</h2>
    <p>
      We aren't at the end of the optimizations that could be made.
      TODO: mention emitter frustum culling, precise per-particle culling, SW rasterization for small particles (mention Nanite), adding more particle attributes (like rotation, angular velocity), culling precipitation with shadow map, etc.
    </p>
  </body>
</html>